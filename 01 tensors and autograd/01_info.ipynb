{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E8KtDqFlrcm"
   },
   "source": [
    "# Фреймворк PyTorch для разработки искусственных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "https://qudata.com/ml/ru/NN_Base_Torch_Graph.html\n",
    "\n",
    "* Соглашение о именовании в PyTorch гласит, что любая функция вида xxx возвращает новый тензор, т.е. является immutable функцией. В противоположность ей функция вида xxx_ изменяет изначальный тензор, т.е. является mutable функцией. Последние ещё носят название inplace функций. \n",
    "Почти для любой immutable функции в PyTorch существует её собрат. Однако бывает и так, что функция существует лишь в каком-то одном варианте. По понятным причинам, функции, изменяющие размер тензора всегда являются immutable.\n",
    "\n",
    "* print(f\"Поддерживается ли CUDA : {torch.cuda.is_available()}\")<br>\n",
    "print(f'Количество гпу девайсов: {torch.cuda.device_count()}')<br>\n",
    "print(f\"Характеристики видеокарты : {torch.cuda.get_device_properties(0)}\")<br>\n",
    "print(f\"Удаляем всю незанятую память через torch.cuda.empty_cache()\")<br>\n",
    "\n",
    "* Но следует запомнить что .cuda() immutable функция. Т.е. она возвращает новый тензор, а не перезаписывает существующий.\n",
    "\n",
    "* requires_grad заразителен. Это означает, что когда тензор создается с помощью других тензоров, для параметра requires_grad результирующего тензора будет установлено значение True, если хотя бы один из тензоров, используемых для создания, имеет для параметра requires_grad значение True.\n",
    "\n",
    "* Можно использовать функцию-член is_leaf, чтобы определить, является ли переменная листовым тензором или нет. Листовые тензоры - это тензоры, которые мы подаем в нашу систему вычислений. Еще это можно понять ка АРГУМЕНТ функции. То есть листовой тензор это независимая переменная типо.\n",
    "\n",
    "* Когда мы делаем backward делаем расчет всех градиентов сети (считаем градиенты всех листовых узлов). Если их не посчитать, не сделать backward, то функция `.grad` ничего нам не выдаст!\n",
    "\n",
    "1) requires_grad\n",
    "\n",
    "Это атрибут класса Tensor. По умолчанию это False. Это удобно, когда вам нужно заморозить некоторые слои и запретить им обновлять параметры во время тренировки. Вы можете просто установить для параметра requires_grad значение False, и эти тензоры не будут участвовать в графе вычислений.\n",
    "\n",
    "2) torch.no_grad()\n",
    "\n",
    "Когда мы вычисляем градиенты, нам нужно кэшировать входные значения и промежуточные функции, поскольку они могут потребоваться для вычисления градиента позже.  Если нам нужно сохранить эти значения для вычисления градиента во время обратного прохода, это повлияет на объем памяти, занимаемой сетью.\n",
    "\n",
    "С использованием torch.no_grad мы выполняем вывод нашей нейронной сети и мы не вычисляем градиенты и, следовательно, нам не нужно хранить эти значения. Фактически, во время вывода графа вычислений создавать не нужно, так как это приведет к бесполезному потреблению памяти.\n",
    "\n",
    "* Так как листовой тензор x не пересоздаётся, у него необходимо обнулять градиенты иначе они начнут суммироваться на следующих итерациях цикла (с каждой эпохой). Поэтому мы делаем `optimizer.zero_grad()`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Кратко **Алгоритм обучения**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1789, 0.7259], requires_grad=True), tensor([-0.1581,  1.6218]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, requires_grad=True)\n",
    "y = torch.randn(2, requires_grad=False)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# слой\n",
    "linear = nn.Linear(2, 2)\n",
    "# loss\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.8060, grad_fn=<MseLossBackward>)  \n",
      "loss_item : 0.8060101270675659\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss, ' \\nloss_item :', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w grad:  tensor([[ 0.0238,  0.0964],\n",
      "        [-0.2258, -0.9166]])\n",
      "b grad:  tensor([ 0.1329, -1.2627])\n",
      "\n",
      "BEFORE:\n",
      " w:  Parameter containing:\n",
      "tensor([[ 0.3114, -0.6989],\n",
      "        [-0.5633,  0.0163]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([0.4264, 0.4481], requires_grad=True) \n",
      "\n",
      "AFTER:\n",
      "w:  Parameter containing:\n",
      "tensor([[ 0.3111, -0.6998],\n",
      "        [-0.5610,  0.0254]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([0.4250, 0.4607], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Перед тем как считать градиенты и менять веса, нам нужно обнулить градиенты\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "print('w grad: ', linear.weight.grad)\n",
    "print('b grad: ', linear.bias.grad)\n",
    "print()\n",
    "# Веса до\n",
    "print('BEFORE:\\n','w: ', linear.weight)\n",
    "print('b: ', linear.bias, '\\n')\n",
    "\n",
    "# Делаем шаг оптимизатора\n",
    "optimizer.step()\n",
    "\n",
    "# Веса после\n",
    "print('AFTER:\\n''w: ', linear.weight)\n",
    "print('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS0-beUdHdMi"
   },
   "source": [
    "- Материалы и ДЗ берите с ноутбуков Web*.ipynb\n",
    "- 10 занятий, 2 дня в неделю\n",
    "- Тайминг занятий ~1.5 часа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JT3FtljAhgw"
   },
   "source": [
    "<!-- <img src='https://drive.google.com/uc?export=view&id=1v51-gWkPgQmtIhcGpmwuw81TGwMz7aM5'> -->\n",
    "<img src='images/Pytorch_logo.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJo6HP61Ahgy"
   },
   "source": [
    "### План \n",
    "\n",
    "1. Введение в PyTorch. Тензоры, автодифференцирование\n",
    "2. Feed-forward нейронные сети на Pytorch\n",
    "3. Dataloader, Dataset в Pytorch. Продвинутые методы оптимизации\n",
    "4. Сверточные сети в Pytorch. Классификация изображений. Предобученные сети в Pytorch\n",
    "5. Составная лосс-функция. Сегментация изображений.\n",
    "6. Сверточные сети применительно к текстовым задачам. Эмбеддинг-слои. Классификация новостей одномерными свертками.\n",
    "7. Рекурентные нейронные сети. GRU, LSTM на Pytorch. Задача NER.\n",
    "8. GAN на Pytorch.\n",
    "9. Bert и Transformer на Pytorch\n",
    "10. Face Detection and Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoFHbsJClrcw"
   },
   "source": [
    "# PyTorch, вводное занятие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6q9v2uVflrcw"
   },
   "source": [
    "### План занятия:\n",
    "\n",
    "* Установка\n",
    "* Тензоры\n",
    "* Введение в синтаксис pytorch и Тензорные вычисления\n",
    "* Вычислительный граф и Автоматическое диференцирование\n",
    "* Погружаемся в детали\n",
    "* Tensorflow vs PyTorch\n",
    "* Где полученные знания можно применить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsbYTszFlrcy"
   },
   "source": [
    "# 0. Установка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxkIdBBrlrcz",
    "outputId": "1fb2a3aa-53ef-42af-a501-13a9ac45c948"
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz-hpRAclrc4"
   },
   "source": [
    "# 1. Тензоры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioO3fIeclrc4"
   },
   "source": [
    "Тензоры схожи с ndarrays в NumPy, с добавлением того, что тензоры могут быть использованы на GPU для ускорения вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajgxH0z_AhhB"
   },
   "source": [
    "### Тензоры\n",
    "\n",
    "Тензор - основная структура данных в библиотеках машинного обучения, которая похожа на массив Numpy. Что-то вроде n-мерной матрицы или массива массивов.Тензоры обеспечивают ускорение различных математических операций. Эти операции при выполнении в большом количестве в глубоком обучении имеют огромное значение в скорости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZzcooQUe83I"
   },
   "source": [
    "<!-- <img src='https://drive.google.com/uc?export=view&id=1pDiSoBIL8IBpIFq3R4OKGRW3YseBRvFm'> -->\n",
    "<img src='images/scalar-vector-matrix-tensor.jpg'>\n",
    "\n",
    "\n",
    "Визуализизация тензора с более чем двумя осями:\n",
    "\n",
    "<!-- <img src='https://drive.google.com/uc?Export=view&id=1C6pu0iDx1Ugz2OMyE9d6KZH9IcN3-STG'> -->\n",
    "<img src='images/3-axis_numpy.png'>\n",
    "<!-- <img src='https://drive.google.com/uc?export=view&id=1cmVLwGNLc8fkDpmNZreTecMNCXgD6zGl'> -->\n",
    "<img src='images/3-axis_front.png'>\n",
    "<!-- <img src='https://drive.google.com/uc?export=view&id=1XiGSZVsVQrlH279eu2IK1bekSvccX6aT'> -->\n",
    "<img src='images/3-axis_block.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Wwd8OUFlrc-"
   },
   "source": [
    "# 2. Введение в синтаксис pytorch и Тензорные вычисления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oo6pzUghlrc-"
   },
   "source": [
    "[База от pytorch](https://pytorch.org/tutorials/beginner/basics/intro.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cr4ur_8Llrc_"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjBbSSOXlrdB"
   },
   "source": [
    "### 2.1 Тензоры в pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsP_QDjylrdC"
   },
   "source": [
    "Тип данных, хранимых тензором, отражается в имени его конструктора. Конструктор без параметров вернёт специальное значение — тензор без размерности, который нельзя использовать ни в каких операциях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor()\n",
    "a = torch.Tensor()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc2jfbOalrdD"
   },
   "source": [
    "Типы тензоров в pytorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRGslGDYlrdE"
   },
   "source": [
    "torch.HalfTensor      # 16 бит, с плавающей точкой  \n",
    "torch.FloatTensor     # 32 бита,  с плавающей точкой  \n",
    "torch.DoubleTensor    # 64 бита, с плавающей точкой  \n",
    "\n",
    "torch.ShortTensor     # 16 бит, целочисленный, знаковый  \n",
    "torch.IntTensor       # 32 бита, целочисленный, знаковый  \n",
    "torch.LongTensor      # 64 бита, целочисленный, знаковый  \n",
    "\n",
    "torch.CharTensor      # 8 бит, целочисленный, знаковый  \n",
    "torch.ByteTensor      # 8 бит, целочисленный, беззнаковый  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3npMKfhHlrdF"
   },
   "source": [
    "torch.Tensor является сокращённым названием для torch.FloatTensor. Так же в последних версиях существует автоматическое приведение типов, если типы не сопоставимы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mP6jj5ImlrdF",
    "outputId": "301ab4df-8efc-4b9d-ed77-ff30359b0a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([2.], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([1.0])\n",
    "b = torch.DoubleTensor([2.0])\n",
    "print(a)\n",
    "print(b)\n",
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULPsrNnxlrdH"
   },
   "source": [
    "Но где-то могут возникать проблемы в виду разных типов. Для этого предусмотрена возможность явного приведения типов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mzydn0ntlrdI",
    "outputId": "8ff17cf2-bef9-4bde-ec6b-38c79731f048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.IntTensor\n",
      "torch.ByteTensor\n"
     ]
    }
   ],
   "source": [
    "a = torch.IntTensor([1])\n",
    "print(a.type())\n",
    "a = a.byte()\n",
    "print(a.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDpxFj1mlrdJ",
    "outputId": "358f2ba6-486d-470b-8b00-989bbc720088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78WC03sMlrdK"
   },
   "source": [
    "### 2.2 Немного о различиях в функциях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hll1Lq_MlrdK"
   },
   "source": [
    "Соглашение о именовании в PyTorch гласит, что любая функция вида xxx возвращает новый тензор, т.е. является immutable функцией. В противоположность ей функция вида xxx_ изменяет изначальный тензор, т.е. является mutable функцией. Последние ещё носят название inplace функций. \n",
    "Почти для любой immutable функции в PyTorch существует её собрат. Однако бывает и так, что функция существует лишь в каком-то одном варианте. По понятным причинам, функции, изменяющие размер тензора всегда являются immutable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5sdx0omlrdL"
   },
   "source": [
    "По поводу всех функций прошу [сюда](https://pytorch.org/docs/master/tensors.html). А сейчас мы коснемся лишь самых важных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swyfZlVrlrdM"
   },
   "source": [
    "### 2.3 Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_XGiOlRlrdV"
   },
   "source": [
    "Начнем с того, как мы можем задать наш тензор. Полный список функций можно посмотреть в [официальном источнике](https://pytorch.org/docs/stable/torch.html) под заголовком Creation Ops. Вот некоторые разные варианты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBIvfmmzlrdW",
    "outputId": "035136c8-4df1-4a77-bd35-bc5871ca3f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of tensor :  torch.FloatTensor\n",
      "Simple way: tensor([1.0000, 1.4000, 2.5000])\n",
      "Via type : tensor([1.0000, 1.4000, 2.5000])\n",
      "Zeros:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Превращаем а в нули : tensor([0., 0., 0.])\n",
      "Заполним тензор константой : tensor([5., 5., 5.])\n",
      "Range: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Complicated range: tensor([ 4,  6,  8, 10])\n",
      "Space: tensor([1.0000, 1.6000, 2.2000, 2.8000, 3.4000, 4.0000])\n"
     ]
    }
   ],
   "source": [
    "a = [1. , 1.4 , 2.5]\n",
    "a_tensor = torch.tensor(a)\n",
    "print(f\"type of tensor : \", a_tensor.type())\n",
    "print(f\"Simple way: {torch.tensor(a)}\")\n",
    "print(f\"Via type : {torch.FloatTensor(a)}\")\n",
    "print(f\"Zeros:\\n {torch.zeros((2, 3))}\")\n",
    "print(f\"Превращаем а в нули : {a_tensor.zero_()}\")\n",
    "print(f\"Заполним тензор константой : {a_tensor.fill_(5)}\")\n",
    "print(f\"Range: {torch.arange(0, 10)}\")\n",
    "print(f\"Complicated range: {torch.arange(4, 12, 2)}\")\n",
    "print(f\"Space: {torch.linspace(1, 4, 6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIf4MP-ulrdX"
   },
   "source": [
    "### 2.4 Случайная выборка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rGBzeeKlrdX"
   },
   "source": [
    "Теперь про то, как мы можем генерировать случайнные значения в наших тензорах. Полный список функций можно посмотреть по ссылке выше под заголовком Random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-vKQwM1olrdY",
    "outputId": "f7eb7d8f-53f2-41d7-890a-805fad984062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 0 to 1: tensor([0.7200])\n",
      "Vector from 0 to 1: tensor([0.8901, 0.5843, 0.7903, 0.8853, 0.4487])\n",
      "Vector from a normal distribution with mean 0 and variance 1: tensor([[ 0.3113, -0.5383, -0.5154],\n",
      "        [ 0.4047, -1.0422, -0.2166]])\n",
      "Vector from 0 to 10: tensor([4, 1, 8, 7, 4])\n",
      "Непрерывное равномерное распределение : tensor([2.8341, 2.6746, 1.5547])\n"
     ]
    }
   ],
   "source": [
    "print(f\"From 0 to 1: {torch.rand(1)}\")\n",
    "print(f\"Vector from 0 to 1: {torch.rand(5)}\")\n",
    "print(f\"Vector from a normal distribution with mean 0 and variance 1: {torch.randn(2, 3)}\")\n",
    "print(f\"Vector from 0 to 10: {torch.randint(10, size=(5,))}\")\n",
    "print(f\"Непрерывное равномерное распределение : {a_tensor.uniform_(0, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1apoSI34lrda"
   },
   "source": [
    "### 2.5 Математические операции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eogPvK3olrdb"
   },
   "source": [
    "С матричными операциями так же все аналогично с тем же numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMpVDkyOlrdb",
    "outputId": "87e89d12-39aa-46b8-d399-13559a1417ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "shape: torch.Size([10])\n",
      "b: tensor([-10.0000,  -7.7778,  -5.5556,  -3.3333,  -1.1111,   1.1111,   3.3333,\n",
      "          5.5556,   7.7778,  10.0000])\n",
      "shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10).type(torch.FloatTensor)\n",
    "b = torch.linspace(-10, 10, 10)\n",
    "print(f\"a: {a}\\nshape: {a.size()}\")\n",
    "print(f\"b: {b}\\nshape: {b.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLvfZBI5niyi",
    "outputId": "025a9677-6aa4-433f-b44c-9d9336fe7631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b: tensor([-10.0000,  -6.7778,  -3.5556,  -0.3333,   2.8889,   6.1111,   9.3333,\n",
      "         12.5556,  15.7778,  19.0000]),\n",
      " a * b: tensor([ -0.0000,  -7.7778, -11.1111, -10.0000,  -4.4444,   5.5556,  20.0000,\n",
      "         38.8889,  62.2222,  90.0000])\n",
      "a + b: tensor([-10.0000,  -6.7778,  -3.5556,  -0.3333,   2.8889,   6.1111,   9.3333,\n",
      "         12.5556,  15.7778,  19.0000]),\n",
      " a * b: tensor([ -0.0000,  -7.7778, -11.1111, -10.0000,  -4.4444,   5.5556,  20.0000,\n",
      "         38.8889,  62.2222,  90.0000])\n",
      "a + b: tensor([-10.0000,  -6.7778,  -3.5556,  -0.3333,   2.8889,   6.1111,   9.3333,\n",
      "         12.5556,  15.7778,  19.0000]),\n",
      " a * b: tensor([100.0000,  52.7160,  19.7531,   1.1111,  -3.2099,   6.7901,  31.1111,\n",
      "         69.7531, 122.7160, 190.0000])\n"
     ]
    }
   ],
   "source": [
    "print(f\"a + b: {a + b},\\n a * b: {a * b}\")\n",
    "print(f\"a + b: {a.add(b)},\\n a * b: {a.mul(b)}\") # вычитание sub, деление - div\n",
    "print(f\"a + b: {a.add_(b)},\\n a * b: {a.mul_(b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8ev2q3OnkSg",
    "outputId": "7811f388-007e-4c5f-9749-3e040a9fe2c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Экспонента : tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03]),\n",
      " tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03]), \n",
      " tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03])\n",
      "Логарифм : tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Модуль : tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(10).type(torch.FloatTensor)\n",
    "\n",
    "print(f\"Экспонента : {a.exp()},\\n {torch.exp(a)}, \\n {a.exp_()}\")\n",
    "print(f\"Логарифм : {a.log()}\")\n",
    "print(f\"Модуль : {a.abs()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gqhs-wzFnlqm",
    "outputId": "e3bcefe3-9ebd-4912-e077-d432fc4d7d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скалярное произведение: 111618.328125\n",
      "Mean: 1281.830810546875, STD: 2571.337890625\n",
      "Sum: 12818.30859375, Min: 1.0, Max: 8103.083984375\n"
     ]
    }
   ],
   "source": [
    "print(f\"Скалярное произведение: {a.dot(b)}\")\n",
    "print(f\"Mean: {a.mean()}, STD: {a.std()}\")\n",
    "print(f\"Sum: {a.sum()}, Min: {a.min()}, Max: {a.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqJzUTbESuO8",
    "outputId": "1717d3ba-f3f5-479b-fa2a-1eec7efe7fae",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
       "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8FYpFBMnm9_",
    "outputId": "5d63f464-92c7-43be-fe15-1053f282a7bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape:\n",
      "tensor([[1.0000e+00],\n",
      "        [2.7183e+00],\n",
      "        [7.3891e+00],\n",
      "        [2.0086e+01],\n",
      "        [5.4598e+01],\n",
      "        [1.4841e+02],\n",
      "        [4.0343e+02],\n",
      "        [1.0966e+03],\n",
      "        [2.9810e+03],\n",
      "        [8.1031e+03]])\n",
      "shape: torch.Size([10, 1])\n",
      "Повторения:\n",
      "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.7183e+00, 2.7183e+00, 2.7183e+00, 2.7183e+00, 2.7183e+00],\n",
      "        [7.3891e+00, 7.3891e+00, 7.3891e+00, 7.3891e+00, 7.3891e+00],\n",
      "        [2.0086e+01, 2.0086e+01, 2.0086e+01, 2.0086e+01, 2.0086e+01],\n",
      "        [5.4598e+01, 5.4598e+01, 5.4598e+01, 5.4598e+01, 5.4598e+01],\n",
      "        [1.4841e+02, 1.4841e+02, 1.4841e+02, 1.4841e+02, 1.4841e+02],\n",
      "        [4.0343e+02, 4.0343e+02, 4.0343e+02, 4.0343e+02, 4.0343e+02],\n",
      "        [1.0966e+03, 1.0966e+03, 1.0966e+03, 1.0966e+03, 1.0966e+03],\n",
      "        [2.9810e+03, 2.9810e+03, 2.9810e+03, 2.9810e+03, 2.9810e+03],\n",
      "        [8.1031e+03, 8.1031e+03, 8.1031e+03, 8.1031e+03, 8.1031e+03]])\n",
      "shape: torch.Size([10, 5])\n",
      "Транспонирование:\n",
      "tensor([[1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03],\n",
      "        [1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03],\n",
      "        [1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03],\n",
      "        [1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03],\n",
      "        [1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03]])\n",
      "shape: torch.Size([5, 10])\n",
      "Уникальные элементы: tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reshape:\\n{a.reshape(-1, 1)}\\nshape: {a.reshape(-1, 1).size()}\")\n",
    "c = a.reshape(-1, 1).repeat(1, 5)\n",
    "print(f\"Повторения:\\n{c}\\nshape: {c.size()}\")\n",
    "print(f\"Транспонирование:\\n{c.T}\\nshape: {c.T.size()}\")\n",
    "print(f\"Уникальные элементы: {torch.unique(c)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrI9Y6-klrdd"
   },
   "source": [
    "### 2.6 Индексирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWKhVxkulrdd",
    "outputId": "c6a342a6-eb2a-4ccd-d0c8-ae58402a909c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array:\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
      "        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
      "        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
      "        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\n",
      "shape: torch.Size([10, 10])\n",
      "Get first column: tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Get last row: tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "Add new aхis:\n",
      "tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]],\n",
      "\n",
      "        [[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n",
      "\n",
      "        [[50, 51, 52, 53, 54, 55, 56, 57, 58, 59]],\n",
      "\n",
      "        [[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]],\n",
      "\n",
      "        [[70, 71, 72, 73, 74, 75, 76, 77, 78, 79]],\n",
      "\n",
      "        [[80, 81, 82, 83, 84, 85, 86, 87, 88, 89]],\n",
      "\n",
      "        [[90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]])\n",
      "shape: torch.Size([10, 1, 10])\n",
      "Specific indexing:\n",
      "tensor([[47, 48, 49],\n",
      "        [57, 58, 59]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(100).reshape(10, 10)\n",
    "print(f\"Array:\\n{a}\\nshape: {a.size()}\")\n",
    "print(f\"Get first column: {a[:, 0]}\")\n",
    "print(f\"Get last row: {a[-1, :]}\")\n",
    "print(f\"Add new aхis:\\n{a[:, np.newaxis]}\\nshape: {a[:, np.newaxis].size()}\")\n",
    "print(f\"Specific indexing:\\n{a[4:6, 7:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13, 14, 15, 16],\n",
       "        [21, 22, 23, 24, 25, 26],\n",
       "        [31, 32, 33, 34, 35, 36]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:4, 1:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxJ36RNblrde"
   },
   "source": [
    "### 2.7 Из numpy в pytorch и обратно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Von-vTQxlrdk",
    "outputId": "6155c9fb-bd94-4c75-c492-21ebb4d46d4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04751261, -0.34019986,  1.4863137 , -0.45916462],\n",
       "       [ 1.9454087 ,  1.1148572 , -0.15050705,  1.3621099 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.normal(mean=torch.zeros(2,4))\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQl1YKAVlrdl",
    "outputId": "8156caf2-5bcb-4e22-f327-53e9bb270c55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4299,  0.0341, -0.9457,  0.6760],\n",
       "        [ 0.4965, -0.3187, -1.1949,  0.3267]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.normal(size=(2, 4))\n",
    "torch.from_numpy(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oB-V0qAFlrdm"
   },
   "source": [
    "### 2.8 CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgH4-Qsklrdm"
   },
   "source": [
    "torch.cuda - это пакет для поддержки CUDA. Он поддерживает такую же функциональность как и CPU, но использует CUDA ядра для вычислений. С полным функционалом можно ознакомиться [здесь](https://pytorch.org/docs/stable/cuda.html?highlight=cuda#module-torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKi3yXWzlrdn",
    "outputId": "aa65a82d-7cf8-4ea8-f50e-0a90b5c40ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поддерживается ли CUDA : True\n",
      "Количество гпу девайсов: 1\n",
      "Характеристики видеокарты : _CudaDeviceProperties(name='NVIDIA GeForce GTX 1050 Ti', major=6, minor=1, total_memory=4095MB, multi_processor_count=6)\n",
      "Удаляем всю незанятую память через torch.cuda.empty_cache()\n"
     ]
    }
   ],
   "source": [
    "print(f\"Поддерживается ли CUDA : {torch.cuda.is_available()}\")\n",
    "print(f'Количество гпу девайсов: {torch.cuda.device_count()}')\n",
    "print(f\"Характеристики видеокарты : {torch.cuda.get_device_properties(0)}\")\n",
    "print(f\"Удаляем всю незанятую память через torch.cuda.empty_cache()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYuP3-cHlrdo"
   },
   "source": [
    "Давайте посмотрим на практике как работать с cuda. Допустим мы инициализуем два тензора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDl0l9wQlrdo",
    "outputId": "4d44e309-85fe-403e-b7bf-4706e64fbe5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[-0.0090,  0.5637, -0.9238, -1.9292],\n",
      "        [-1.0238, -0.6663, -0.8012,  2.0625]])\n",
      "b:\n",
      "tensor([[ 0.2372,  1.0486, -1.8579, -0.3627],\n",
      "        [ 1.5180,  1.0619, -2.5942,  0.0567]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.normal(mean=torch.zeros(2, 4))\n",
    "b = torch.normal(mean=torch.zeros(2, 4))\n",
    "print(f\"a:\\n{a}\\nb:\\n{b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1K9I_VKlrdp"
   },
   "source": [
    "Наши тензоры автоматом загружены в память cpu. Но мы легко можем перевести их на cpu таким способом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDb6ruPvlrdq",
    "outputId": "82877a6b-d312-4ad5-da82-5604d3f597c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0090,  0.5637, -0.9238, -1.9292],\n",
       "        [-1.0238, -0.6663, -0.8012,  2.0625]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.cuda()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha5DoFO5lrdq"
   },
   "source": [
    "Теперь, если мы попробуем сложить эти два тензора, то у нас вылезет ошибка, т.к. один тензор на cpu, а другой на cuda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "UGwUNC2xlrdw",
    "outputId": "7c1514ca-0217-40e2-b412-315c9f7ee53b"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc627l3ulrdw"
   },
   "source": [
    "Мы не можем производить никакие операции с тензорами, находящимеся на разных устройствах. Что бы сложить их нам нужно оба тензора перевести на одно устройство:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xv7Vbf0glrdx",
    "outputId": "925a8377-51c9-4b37-acd6-6d8d26afce30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2282,  1.6124, -2.7817, -2.2920],\n",
       "        [ 0.4942,  0.3956, -3.3954,  2.1192]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-WcdeyTlrdx",
    "outputId": "9df2677f-edf9-47e2-fbf0-ef43a46f1595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2282,  1.6124, -2.7817, -2.2920],\n",
       "        [ 0.4942,  0.3956, -3.3954,  2.1192]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cpu() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmcJ4-dYlrdz",
    "outputId": "378233b1-d36d-41f2-a43d-399d311eade4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2282,  1.6124, -2.7817, -2.2920],\n",
       "        [ 0.4942,  0.3956, -3.3954,  2.1192]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a + b.cuda()).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBhzRlf5lrdz"
   },
   "source": [
    "Так же мы можем задать следующее определение устройства. Если  есть куда, то выбираем куду. В ином случае - цпу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_7usJoelrd0",
    "outputId": "a26736d1-9935-4958-cffb-23a4143a7a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4RrmCBTlrd0"
   },
   "source": [
    "У каждого тензора есть поле device, которое по умолчанию стоит cpu. Но мы можем менять его при инициализации или в процессе использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tf4O-Jbzlrd7",
    "outputId": "783bdf47-a4b1-4054-a1f2-e8f4563c3619"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1333, -0.0253,  0.5203,  0.0808,  0.2448,  2.1273, -0.4457, -0.2777,\n",
       "         -0.0204, -0.6867],\n",
       "        [ 1.2116,  1.2338, -0.5203, -1.0842,  0.5538, -0.0122, -0.7851,  2.0841,\n",
       "          0.8503, -0.8356],\n",
       "        [-1.1240,  1.0065,  1.1312, -0.4775, -1.0696,  0.0203, -0.4731,  0.9560,\n",
       "         -0.5914, -0.2986],\n",
       "        [ 0.6311,  0.8227, -0.4904,  0.0420,  0.2279,  1.0566,  1.0266,  0.4820,\n",
       "         -1.2351, -1.5691],\n",
       "        [-0.1493,  0.1509,  0.5439, -0.7965,  0.6963,  2.0964,  1.3630, -1.0720,\n",
       "         -0.7200,  0.5153],\n",
       "        [-0.7107, -0.0682, -0.5090,  1.0528,  0.4610, -0.8511,  0.1332, -0.3104,\n",
       "         -0.0027,  0.4975],\n",
       "        [ 0.5023,  0.7567,  0.6967, -0.0904,  1.1094, -0.2989, -1.9168,  0.6747,\n",
       "          0.9111, -0.4194],\n",
       "        [-0.5071,  1.3227, -0.6994,  0.7576,  0.5750, -1.7438, -0.3435, -0.2424,\n",
       "          0.9906,  1.3603],\n",
       "        [ 0.3458,  0.6506, -1.4511,  0.5815,  0.2965, -0.3876,  0.6771, -0.0368,\n",
       "         -0.1034,  0.3903],\n",
       "        [ 1.0933, -1.6665, -0.6570,  1.4246,  0.5066, -0.6933,  0.3787,  0.0383,\n",
       "          0.2013, -0.1392]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(10, 10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQwfJX44lrd8",
    "outputId": "a91be434-4a4b-4137-a7c5-1e226c63f526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor((2 ,3))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtemnxcGlrd9"
   },
   "source": [
    "Переместить можно не только a.cuda(), но и так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrYYeQ2Ylrd9",
    "outputId": "318323ae-cc85-4eac-8dbc-2f368d17d7e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJfvB_s_lrd-"
   },
   "source": [
    "Но следует запомнить что .cuda() immutable функция. Т.е. она возвращает новый тензор, а не перезаписывает существующий a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHVkYlxWlrd-",
    "outputId": "2d67de0a-831c-4410-f6cb-2fcdda945086"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r-u4QZ3lrd_"
   },
   "source": [
    "Как видим наш тензор a все на том же cpu. Что бы интерпретатор запомнил что a у нас на куде необходимо присвоить значение выражение в тензор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "8PZP4VMqlrd_"
   },
   "outputs": [],
   "source": [
    "a = a.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSnuqWi4lreA",
    "outputId": "ed2c4458-0fd7-478d-a8d0-ec50f3d3bbca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiV-LOESlreG"
   },
   "source": [
    "Проверяем, находится ли сейчас тензор на куде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6w2LyZpklreH",
    "outputId": "9c0011e4-9932-42bb-a558-36c9627d007e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN3pziw3r0kf"
   },
   "source": [
    "# 3. Вычислительный граф и Автоматическое дифференцирование\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYIltf84lreJ"
   },
   "source": [
    "\n",
    "### 3.1 Вычислительный граф\n",
    "\n",
    "Вычислительный граф — это иллюстрированная запись какой-либо функции, состоящая из вершин и рёбер. Вершины (или узлы) — вычислительные операции, которые необходимо выполнить, а рёбра связывают их в определённую последовательность.\n",
    "\n",
    "Автоматическое дифференцирование - строительный блок не только в Pytorch, но и в каждой другой DL библиотеке. Движок автоматического дифференцирования в Pytorch называет [Autograd](https://pytorch.org/docs/stable/autograd.html). \n",
    "\n",
    "Современные архитектуры нейронных сетей могут иметь миллионы обучающихся параметров. С вычислительной точки зрения тренировка сети состоит из двух фаз:\n",
    "\n",
    "1) Прямой проход для вычисления значения функции потерь.  \n",
    "2) Обратный проход для вычисления градиентов обучаемых параметров.\n",
    "\n",
    "Прямой проход весьма прямолинеен: выход одного слоя является входом другого.\n",
    "Обратный проход немного сложнее, поскольку он требует от нас использования цепного правила для вычисления градиентов весов относительно функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTUPg57vAhg6"
   },
   "source": [
    "Ниже представлен простой пример вычислительного графа для вычисления выражения $\\sigma(x*w_1 + w_0)$. Можно разбить вычисление на следующие шаги:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DEEdtooAhg6"
   },
   "source": [
    "<!-- <img src='https://drive.google.com/uc?export=view&id=1jCTO6zBGyE8sYkkSv_6NENdFOiwuJCMC' width=600> -->\n",
    "<img src='images/computational_graph.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJMGxYF6Ahg7"
   },
   "source": [
    "Преимущества использования вычислительного графа в том, что каждый узел является независимым функционирующим куском кода, если получит все необходимые входные данные. Это позволяет  оптимизировать производительность при выполнении расчетов, используя многоканальную обработку, параллельные вычисления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gbHTyn5lreo"
   },
   "source": [
    "### 3.2 PyTorch Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZHQDshMlreo"
   },
   "source": [
    "Теперь, когда мы понимаем, что такое вычислительный граф, вернемся к PyTorch и разберемся, как это реализовано в PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0415zzOllrep"
   },
   "source": [
    "#### 3.2.1 Tензоры и requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUUpc9TGlrep"
   },
   "source": [
    "Как мы видели выше, тензор - это структура данных, которая является фундаментальным строительным блоком PyTorch и они во многом похожи на массивы numpy, за исключением того, что в отличие от numpy, тензоры предназначены для использования преимуществ параллельных вычислений графического процессора(GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnhj6vjolreq",
    "outputId": "193dcb0b-3b8a-4ca8-f706-fcb6dd3ae7a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8515e+28, 6.8794e+11, 2.7253e+20, 3.0866e+29, 7.2296e+31],\n",
       "        [5.6015e-02, 7.0374e+22, 6.9983e+28, 1.2412e+28, 1.0304e+21],\n",
       "        [2.7495e+26, 5.6502e-02, 1.8728e+31, 7.3867e+20, 2.0027e-19]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tsr = torch.Tensor(3,5)\n",
    "tsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAM31O5ylrer"
   },
   "source": [
    "Вот он Tensor похожий на numpy ndarray. Структура данных, которая позволяет быстро выполнять операции линейной алгебры. Что бы сделать тензор обучающимся и мы бы смогли вычислить его градиент, необходимо поставить его параметр requires_grad в значение True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQX1h7uvlrer"
   },
   "source": [
    "requires_grad можно менять как при инициализации тензора, так и после:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn((3,3), requires_grad=True)\n",
    "print(t1.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NjB1sRIMlrex",
    "outputId": "745bc24e-3c8a-47f9-e2a9-c98e64d717c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.FloatTensor(3, 3)\n",
    "print(t2.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJkO2Yuolrey",
    "outputId": "3f914ed3-3d5c-4e87-9980-6a2f479a4602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "t2.requires_grad = True\n",
    "print(t2.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzX5Atkmlrez"
   },
   "source": [
    "requires_grad заразителен. Это означает, что когда тензор создается с помощью других тензоров, для параметра requires_grad результирующего тензора будет установлено значение True, если хотя бы один из тензоров, используемых для создания, имеет для параметра requires_grad значение True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heK4cN4iq8Kp"
   },
   "source": [
    "*__Вопрос__: в каких ситуациях нам не нужен градиент для переменных?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZ6G8eOqAhhU",
    "outputId": "5a3cf543-a969-44d2-ea2b-a2c7ddb332b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_aXcleXAhhU"
   },
   "source": [
    "В x у нас хранится информация о градиенте. Мы можем получить ее через метод grad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ft_gExlZAhhV"
   },
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go7WnPwfAhhV"
   },
   "source": [
    "В данном случае ничего нет, т.к. мы никаких действий с нашим тензором не производили."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G50J9jHEAhhV"
   },
   "source": [
    "Создадим переменную на основе x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (x**2) + 5.0*x # задание - посчитать производную руками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCl_FwTTAhhW",
    "outputId": "969bbcae-52d7-461b-9033-4e3ccf2dd602"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 6.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwpCO-5hAhhW"
   },
   "source": [
    "Мы вызываем метод backward и передаем ей единичный тензор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "U2RngNdNAhhX"
   },
   "outputs": [],
   "source": [
    "z.backward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMNtkwy6AhhX"
   },
   "source": [
    "И тогда, когда мы выполнили эту функцию - мы вызываем градиент и получаем значение градиента в точке (1, 1, 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXcfyu2FAhhX",
    "outputId": "f8b78f13-01b9-43ff-d26c-cf93f5842e8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 7., 7.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8e4hHAybGqo"
   },
   "source": [
    "<!-- <img src='https://drive.google.com/uc?export=view&id=1jCTO6zBGyE8sYkkSv_6NENdFOiwuJCMC' width=600> -->\n",
    "<img src='images/computational_graph.png' width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7571], grad_fn=<SigmoidBackward>) tensor(0.0590, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1])\n",
    "w1 = torch.tensor([0.417], requires_grad=True)\n",
    "w0 = torch.tensor([0.72], requires_grad=True)\n",
    "a = x * w1\n",
    "b = a + w0\n",
    "sigma = torch.sigmoid(b)\n",
    "mse = torch.nn.functional.mse_loss(sigma, x)\n",
    "print(sigma, mse)\n",
    "mse.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0893]), tensor([-0.0893]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad, w0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7885], grad_fn=<SigmoidBackward>) tensor(0.0448, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1])\n",
    "w1 = torch.tensor([0.417-w1.grad], requires_grad=True)\n",
    "w0 = torch.tensor([0.72-w0.grad], requires_grad=True)\n",
    "a = x * w1\n",
    "b = a + w0\n",
    "sigma = torch.sigmoid(b)\n",
    "mse = torch.nn.functional.mse_loss(sigma, x)\n",
    "print(sigma, mse)\n",
    "mse.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка уменьшилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000], grad_fn=<SigmoidBackward>) tensor(0.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([0.6225], grad_fn=<SigmoidBackward>) tensor(0.1425, grad_fn=<MseLossBackward>)\n",
      "tensor([0.7016], grad_fn=<SigmoidBackward>) tensor(0.0890, grad_fn=<MseLossBackward>)\n",
      "tensor([0.7512], grad_fn=<SigmoidBackward>) tensor(0.0619, grad_fn=<MseLossBackward>)\n",
      "tensor([0.7843], grad_fn=<SigmoidBackward>) tensor(0.0465, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8080], grad_fn=<SigmoidBackward>) tensor(0.0369, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8258], grad_fn=<SigmoidBackward>) tensor(0.0304, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8397], grad_fn=<SigmoidBackward>) tensor(0.0257, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8510], grad_fn=<SigmoidBackward>) tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8603], grad_fn=<SigmoidBackward>) tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8682], grad_fn=<SigmoidBackward>) tensor(0.0174, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8750], grad_fn=<SigmoidBackward>) tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8808], grad_fn=<SigmoidBackward>) tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8860], grad_fn=<SigmoidBackward>) tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8906], grad_fn=<SigmoidBackward>) tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8946], grad_fn=<SigmoidBackward>) tensor(0.0111, grad_fn=<MseLossBackward>)\n",
      "tensor([0.8983], grad_fn=<SigmoidBackward>) tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9017], grad_fn=<SigmoidBackward>) tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9047], grad_fn=<SigmoidBackward>) tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9075], grad_fn=<SigmoidBackward>) tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9101], grad_fn=<SigmoidBackward>) tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9125], grad_fn=<SigmoidBackward>) tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9147], grad_fn=<SigmoidBackward>) tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9167], grad_fn=<SigmoidBackward>) tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9187], grad_fn=<SigmoidBackward>) tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9204], grad_fn=<SigmoidBackward>) tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9221], grad_fn=<SigmoidBackward>) tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9237], grad_fn=<SigmoidBackward>) tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9252], grad_fn=<SigmoidBackward>) tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor([0.9266], grad_fn=<SigmoidBackward>) tensor(0.0054, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "w1 = -10\n",
    "w0 = 10\n",
    "w1g = 0.0\n",
    "w0g = 0.0\n",
    "\n",
    "for i in range(30):\n",
    "    x = torch.FloatTensor([1])\n",
    "    w1 = torch.tensor([w1-w1g], requires_grad=True)\n",
    "    w0 = torch.tensor([w0-w0g], requires_grad=True)\n",
    "    a = x * w1\n",
    "    b = a + w0\n",
    "    sigma = torch.sigmoid(b)\n",
    "    mse = torch.nn.functional.mse_loss(sigma, x)\n",
    "    print(sigma, mse)\n",
    "    mse.backward()\n",
    "    w1g = w1.grad; w0g = w0.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что ошибка падает. И мы получили обученные веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-8.7318], requires_grad=True), tensor([11.2682], requires_grad=True))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXn6KlzWlre0"
   },
   "source": [
    "У каждого тензора есть атрибут grad_fn, который отсылается к функции (математическому оператору), создающему переменную. \n",
    "\n",
    "grad_fn будет равен None, если нет зависимых функций, к примеру, переменная `а`\n",
    "ни от чего не зависит, нет ни какой функции, из которой бы получилась переменная а, а значит и grad_fn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((3,3), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGsqOfzQlre_",
    "outputId": "f6bd4817-ff87-4850-c453-37e66289b74e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grad fn for a is None\n",
      "The grad fn for d is <AddBackward0 object at 0x00000246C6576A90>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad=True)\n",
    "w2 = torch.randn((3,3), requires_grad=True)\n",
    "w3 = torch.randn((3,3), requires_grad=True)\n",
    "w4 = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "b = w1 * a\n",
    "c = w2 * a\n",
    "\n",
    "d = w3 * b + w4 * c\n",
    "\n",
    "L = 10 - d\n",
    "\n",
    "print(\"The grad fn for a is\", a.grad_fn)\n",
    "print(\"The grad fn for d is\", d.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x246ad148790>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhIb7fzAlrfA"
   },
   "source": [
    "Можно использовать функцию-член is_leaf, чтобы определить, является ли переменная листовым тензором или нет. Листовые тензоры - это тензоры, которые мы подаем в нашу систему вычислений. В нашем случае это а:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5QIyVGOlrfB",
    "outputId": "786d3aec-831f-4661-c06f-647428585bb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.is_leaf, w1.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnZelZ9KlrfC",
    "outputId": "06b15315-1853-4f6f-c459-7e8eb922a1d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.is_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMm2QuehlrfD"
   },
   "source": [
    "#### 3.2.2 Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSs52A0rlrfD"
   },
   "source": [
    "Все математические операции в PyTorch реализуются классом [torch.nn.Autograd.Function](https://pytorch.org/docs/stable/autograd.html#function). У этого класса есть две важные функции-члены, на которые нам нужно обратить внимание.\n",
    "\n",
    "Во-первых, это forward функция, которая просто вычисляет выходные данные, используя входные данные.\n",
    "\n",
    "Функция backward принимает входящий градиент, исходящий от части сети перед ней. Как вы можете видеть, градиент, который должен распространяться в обратном направлении от функции f, - это, по сути, градиент, который передается обратно в f от слоев перед ним, умноженный на локальный градиент выходных данных f по отношению к его входам. Именно это и делает обратная функция.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMXS85bmlrfG"
   },
   "source": [
    "Алгоритмически, вот как происходит обратное распространение с графом вычислений. (Не фактическая реализация, только пример):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNm3GMI-lrfG"
   },
   "source": [
    "```\n",
    "\n",
    "def backward(incoming_gradients):\n",
    "    self.Tensor.grad = incoming_gradients\n",
    "\n",
    "    for inp in self.inputs:\n",
    "        if inp.grad_fn is not None:\n",
    "            new_incoming_gradients = incoming_gradient * local_grad(self.Tensor, inp)\n",
    "\n",
    "            inp.grad_fn.backward(new_incoming_gradients)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EtJtoVblrfG"
   },
   "source": [
    "Здесь self.Tensor - это, тензор, созданный Autograd.Function, который использовался в нашем примере.\n",
    "\n",
    "Входящие градиенты и локальные градиенты были описаны выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLVqseSWlrfH"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EJewzsLlrfJ"
   },
   "source": [
    "Чтобы вычислить производные в нашей нейронной сети, мы обычно обращаемся к тензору, представляющему нашу потерю. Затем мы возвращаемся по графику, начиная с узла, представляющего grad_fn наших потерь.\n",
    "\n",
    "Как описано выше, обратная функция рекурсивно вызывается по графику, когда мы возвращаемся. Однажды мы достигаем листового узла, поскольку grad_fn равен None, но прекращаем возвращение по этому пути.\n",
    "\n",
    "Здесь следует отметить, что PyTorch выдает ошибку, если вы вызываете backward () для векторного тензора. Это означает, что вы можете выполнять обратный вызов только для тензорного скалярного значения. В нашем примере, если мы предположим, что a - тензор с векторным значением, и обратимся к L, он выдаст ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "OHnXE1tDlrfJ",
    "outputId": "f32a8893-b509-44b4-e79c-6290b90a0a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.0153,  9.8522, 10.0999],\n",
      "        [10.7516, 10.3412, 10.7203],\n",
      "        [10.1578,  8.6226, 10.5371]], grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m L \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m-\u001b[39m d)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(L)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\synapse182_c111\\lib\\site-packages\\torch\\tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    238\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    239\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    244\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\synapse182_c111\\lib\\site-packages\\torch\\autograd\\__init__.py:141\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    138\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    140\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 141\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\synapse182_c111\\lib\\site-packages\\torch\\autograd\\__init__.py:50\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mones_like(out, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format))\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "a = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad=True)\n",
    "w2 = torch.randn((3,3), requires_grad=True)\n",
    "w3 = torch.randn((3,3), requires_grad=True)\n",
    "w4 = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "b = w1 * a \n",
    "c = w2 * a\n",
    "\n",
    "d = w3 * b + w4 * c \n",
    "\n",
    "L = (10 - d)\n",
    "print(L)\n",
    "\n",
    "L.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd_gEROTlrfK"
   },
   "source": [
    "Это потому, что градиенты могут быть вычислены относительно скалярных значений по определению. Вы не можете точно отличить вектор от другого вектора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETgNADiolrfL"
   },
   "source": [
    "Если вы просто сделаете небольшое изменение в приведенном выше коде, установив L как сумму всех ошибок, наша проблема будет решена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUdyzF2WlrfL",
    "outputId": "254e65f0-725b-4050-927e-3a7186fd254b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(86.3119, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "a = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad=True)\n",
    "w2 = torch.randn((3,3), requires_grad=True)\n",
    "w3 = torch.randn((3,3), requires_grad=True)\n",
    "w4 = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "b = w1 * a \n",
    "c = w2 * a\n",
    "\n",
    "d = w3 * b + w4 * c \n",
    "\n",
    "# Replace L = (10 - d) by \n",
    "L = (10 - d).sum()\n",
    "print(L)\n",
    "\n",
    "L.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUVG6dtolrfN"
   },
   "source": [
    "Как только это будет сделано, вы можете получить доступ к градиентам, вызвав атрибут grad в Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2962,  0.0861, -0.2112],\n",
       "         [ 2.7501,  0.2264,  0.2341],\n",
       "         [ 0.0515, -1.8088,  0.1984]]),\n",
       " tensor([[-1.1672,  0.0476,  0.2247],\n",
       "         [-0.8314, -0.2723, -0.0410],\n",
       "         [ 0.6376,  0.3194,  0.7438]]),\n",
       " tensor([[-0.0568,  0.5241, -0.0314],\n",
       "         [-3.5005,  0.0826,  0.4240],\n",
       "         [ 0.5416, -0.7441, -1.2687]]),\n",
       " tensor([[-1.5757,  1.1784,  0.4623],\n",
       "         [ 0.8881,  0.1128, -0.2071],\n",
       "         [-1.7172, -1.5468,  2.8861]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad, w2.grad, w3.grad, w4.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geQBtfx6lrfQ"
   },
   "source": [
    "#### 3.2.3 Некоторые хитрости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPyuy1PxlrfR"
   },
   "source": [
    "1) requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-adpm4BrlrfR"
   },
   "source": [
    "Это атрибут класса Tensor. По умолчанию это False. Это удобно, когда вам нужно заморозить некоторые слои и запретить им обновлять параметры во время тренировки. Вы можете просто установить для параметра requires_grad значение False, и эти тензоры не будут участвовать в графе вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE87s9HhlrfS"
   },
   "source": [
    "2) torch.no_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOHxTUA-lrfh"
   },
   "source": [
    "Когда мы вычисляем градиенты, нам нужно кэшировать входные значения и промежуточные функции, поскольку они могут потребоваться для вычисления градиента позже.  Если нам нужно сохранить эти значения для вычисления градиента во время обратного прохода, это повлияет на объем памяти, занимаемой сетью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ2CMPD3lrfi"
   },
   "source": [
    "С использованием torch.no_grad мы выполняем вывод нашей нейронной сети и мы не вычисляем градиенты и, следовательно, нам не нужно хранить эти значения. Фактически, во время вывода графа вычислений создавать не нужно, так как это приведет к бесполезному потреблению памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjayYcWxlrfj"
   },
   "source": [
    "PyTorch предлагает для этой цели диспетчер контекста, называемый torch.no_grad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "F5IRJk1Wlrfj"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # inference code goes here \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MMq6SyGlrfk"
   },
   "source": [
    "# 4. Погружаемся в детали"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkcMK9v7lrfl"
   },
   "source": [
    "Все основные модули которые будут рассматриваться ниже находятся в [torch.nn](https://pytorch.org/docs/stable/nn.html#). Все кроме оптимизаторов - они находятся в [torch.optim](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuo6jRyclrfl"
   },
   "source": [
    "### 4.1. Слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqyiBsZslrfm"
   },
   "source": [
    "#### Линейный слой (Линейное преобразование)\n",
    "\n",
    "[pytorch doc](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "\n",
    "$$y = xA^T + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.nn.Linear(\n",
    "    in_features=3,\n",
    "    out_features=2,\n",
    "    bias=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBymHmwoO6Gc",
    "outputId": "9330686b-efc1-4256-8542-dc5044c527b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.4386, -0.5099, -0.0133],\n",
       "         [ 0.5210, -0.0535, -0.2363]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1173, -0.3252], requires_grad=True))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight, layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHImPO4olrgZ"
   },
   "source": [
    "### 4.2 Алгоритм обучения в pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "phZxJlZ5lrgZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leaG6UYdlrgb"
   },
   "source": [
    "1. Для начала нам нужна модель через которую мы будем прогонять данные и получать какой-то результат. Для этого возьмем линейное преобразование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "8p_Y5Ix8lrge"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=2, bias=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(2, 2)\n",
    "linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCYlfLIZlrgf"
   },
   "source": [
    "У слоя в pytorch мы всегда можем посмотреть веса и отклонение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfmjSh0wlrgg",
    "outputId": "2fdf37e2-ccd2-4be6-cfc0-59e924945974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[ 0.1348,  0.5423],\n",
      "        [-0.2783,  0.3441]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.4455,  0.0907], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('w: ', linear.weight)\n",
    "print('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcEQk9xklrgg"
   },
   "source": [
    "2. Теперь нам нужно определить функцию ошибок для подсчета градиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s5fLcGGlrgm"
   },
   "source": [
    "3. Так же нам нужен оптимизатор который будет изменять веса нашей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsft9Mrulrgn"
   },
   "source": [
    "4. Нам нужны данные (х) и верные метки (y) по которым мы поймем правильные ли предсказания делает модель. (В данном случае у нас всего пара значений (данные, метки). О том как организовывать много данных ниже и в дальнейших вебинарах):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aXEA3OGlrgn",
    "outputId": "6dc5310b-8049-41dd-a721-19d0a5f6502e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3494, 0.9497], requires_grad=True), tensor([-0.8295, -0.1928]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, requires_grad=True)\n",
    "y = torch.randn(2, requires_grad=False)\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hT-kKVE7lrgo"
   },
   "source": [
    "5. Перед тем как считать градиенты и менять веса, нам нужно обнулить градиенты хранящиеся в свойстве тензора .grad. Для этого выполняем следующую строчку кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JdByvAdylrgo"
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зануление всех градиентов. После каждой эпохи нам нужно обнулить градиенты оптимизатора? Зачем? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nleewGB2lrgp"
   },
   "source": [
    "6. Затем делаем предсказание на наших данных х, получаем предсказание модели и сохраняем это предсказание в переменную pred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "6vd31Yqxlrgp"
   },
   "outputs": [],
   "source": [
    "pred = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1166, 0.3203], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_xyEM2Ilrgq"
   },
   "source": [
    "7. Переменная pred имеет ту же размерность, что и y. y - это наша правильная метка (ground truth). На этом этапе мы сравниваем предсказанное с реальным и получаем некую численную оценку этого через функцию потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMATmsD0lrgq",
    "outputId": "90094468-7365-43d5-c67d-33320be939e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(0.5792, grad_fn=<MseLossBackward>)  \n",
      "loss_item : 0.5792300701141357\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss, ' \\nloss_item :', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LBFt80flrgr"
   },
   "source": [
    "Стоит отметить, что если мы посмотрим на переменную .grad наших весов и отклонения, то ничего не будет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUIp6jQtlrgs",
    "outputId": "3afe189f-10c7-4559-b134-f691d9d7d3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw:  None\n",
      "dL/db:  None\n"
     ]
    }
   ],
   "source": [
    "print('dL/dw: ', linear.weight.grad) \n",
    "print('dL/db: ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpKSxAbulrgs"
   },
   "source": [
    "Это потому что мы не начинали идти в обратном направлении и высчитывать градиенты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyCJdzdclrgt"
   },
   "source": [
    "8. Что ж, самое время это сделать. Проходим в обратном направлении и вычислим градиенты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "JroDNpxJlrgt"
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlzi3IZflrgu"
   },
   "source": [
    "Теперь если мы посмотрим на grad весов, то уже что-то увидим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2jqTzv5lrgu",
    "outputId": "29357313-457a-4147-dd79-1f3dcbed17ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  tensor([[0.3306, 0.8986],\n",
      "        [0.1793, 0.4873]])\n",
      "b:  tensor([0.9461, 0.5131])\n"
     ]
    }
   ],
   "source": [
    "print('w: ', linear.weight.grad)\n",
    "print('b: ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96uo8Dyulrgv"
   },
   "source": [
    "9. Теперь самое время поменять веса. Для этого надо сделать так называемый шаг оптимизатора. Здесь оптимизатор имея информацию о высчитанных градиентах и значениях весов меняет последние:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOQ1VXTOlrgv",
    "outputId": "41060dcb-17e4-41eb-b33f-8ae49746197f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:\n",
      " w:  Parameter containing:\n",
      "tensor([[ 0.1348,  0.5423],\n",
      "        [-0.2783,  0.3441]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.4455,  0.0907], requires_grad=True) \n",
      "\n",
      "AFTER:\n",
      "w:  Parameter containing:\n",
      "tensor([[ 0.1314,  0.5333],\n",
      "        [-0.2801,  0.3392]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.4550,  0.0856], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Веса до\n",
    "print('BEFORE:\\n','w: ', linear.weight)\n",
    "print('b: ', linear.bias, '\\n')\n",
    "\n",
    "# Делаем шаг оптимизатора\n",
    "optimizer.step()\n",
    "\n",
    "# Веса после\n",
    "print('AFTER:\\n''w: ', linear.weight)\n",
    "print('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HhgLc7nlrhR"
   },
   "source": [
    "#  5. Tensorflow vs PyTorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZvXLj-RlrhS"
   },
   "source": [
    "<!-- <img src='https://drive.google.com/uc?export=view&id=13SNw7d9JGT8lHMrKN2-mNgYrqKqkNXfG'> -->\n",
    "<img src='images/12.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjwlR38ylrhT"
   },
   "source": [
    "* Определение графа - верно для старых версий, в Октябре 2019 года добавили поддержку подобного стиля программирования "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2zYPfsDlrhV"
   },
   "source": [
    "#### Различия:\n",
    "\n",
    "PyTorch разработал Facebook Lab в 2016 году, здесь динамическое определение графа. А Tensorflow разрабатывался командой Google Brains в 2015 и до 2019 года граф определялся только статически.\n",
    "\n",
    "В TensorFlow граф определяется статически перед запуском модели. Связь осуществляется с помощью объекта tf.Session и tf.Placeholder — тензорами, которые во время выполнения программы будут заменены внешними данными.\n",
    "\n",
    "В PyTorch можно определять, изменять и выполнять узлы как вам угодно без дополнительных session- и placeholder-интерфейсов. Когда вы пишите на TensorFlow, иногда кажется, что с моделью можно связываться через несколько крошечных отверстий в кирпичной стене, за которой и прячется модель.\n",
    "\n",
    "Существуют архитектуры нейронных сетей, которые получают преимущества от динамического подхода. RNN со статическим графом длина входной последовательности остается постоянной. Это означает, что необходимо зафиксировать длину предложения на максимальном значении, а все более мелкие последовательности заполнять нулями.\n",
    "\n",
    "Но теперь и в Tensorflow и PyTorch есть возможность динамического определения графа.\n",
    "\n",
    "\n",
    "<!-- <img src='https://drive.google.com/uc?export=view&id=1YceAfoUFkzUo_nHPwpwW8OuklFlQGMwu'> -->\n",
    "<img src='images/debates.png'>\n",
    "\n",
    "[Ссылка](https://chel-center.ru/python-yfc/2020/12/22/pytorch-protiv-tensorflow-dlya-vashego-proekta-glubokogo-obucheniya-python/) на статью где хорошо объясняется различие pytorch от tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3btv8V0QlrhW"
   },
   "source": [
    "# 6. Где полученные знания можно применять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDMm1C17lrhX"
   },
   "source": [
    "pytorch можно использовать в следующих областях:\n",
    "* Распознавание и синтез аудио. Об этом [torchaudio](https://pytorch.org/audio/stable/index.html)  \n",
    "* Так же с инструментом pytorch можно заниматься регрессионными проблемами, прогнозирования временных рядов. Например предсказывать цены на определенные валюты, акции, дома и т.д. [ссылка](https://www.machinelearningmastery.ru/lstm-for-time-series-prediction-de8aeb26f2ca/)\n",
    "* [Задачи NLP](https://pytorchnlp.readthedocs.io/en/latest/index.html#)  \n",
    "* Можно генерировать разную информацию от картинок до текста и аудио.\n",
    "\n",
    "В общем pytorch можно применять везде, где используются нейронные сети.\n",
    "\n",
    "[Бонус](https://www.8host.com/blog/kak-ustanovit-i-ispolzovat-pytorch/): зайдите по ссылке и долистайте до \"Экосистема Pytorch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkJ7emsMxaYF"
   },
   "source": [
    "# Домашнее задание\n",
    "\n",
    "\n",
    "- Срок сдачи 7 дней\n",
    "- Если не успеваете, то после истечения срока в 7 дней на странице ДЗ появляется кнопка о **самостоятельном продлении** сроков еще на 7 дней\n",
    "- Если после 14 дней, то через техподдержку\n",
    "- В выходные дни возможен ревьюер ДЗ\n",
    "\n",
    "\n",
    "Ноутбук: https://colab.research.google.com/drive/1l_ngLK9Ltwkd8Gkv9WwQYGo_ctCs3HvY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfRSfecExTgi"
   },
   "source": [
    "# Дополнительные материалы\n",
    "1. [Pytorch vs Tensorflow in 2020](https://towardsdatascience.com/pytorch-vs-tensorflow-in-2020-fe237862fae1)\n",
    "2. [Официальная документация PyTorch](https://pytorch.org/tutorials/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4TESt3AxXg7"
   },
   "source": [
    "# Определения\n",
    "\n",
    "\n",
    "**Вычислительный граф** — это иллюстрированная запись какой-либо функции, состоящая из вершин и рёбер. Вершины (или узлы) — вычислительные операции, которые необходимо выполнить, а рёбра связывают их в определённую последовательность.\n",
    "\n",
    "Шаги обучения:\n",
    "1. Проход по батчу\n",
    "2. Обнуление градиента\n",
    "3. Предсказание модели на батче\n",
    "4. Подсчет ошибки\n",
    "5. Подсчет градиентов\n",
    "6. Шаг оптимизации\n",
    "7. Логирование информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nfRSfecExTgi",
    "u4TESt3AxXg7"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
